{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition using Image Classification\n",
    "\n",
    "using tensorflow and keras\n",
    "\n",
    "# Convolutional Neural Network\n",
    "\n",
    "One of the most powerful supervised deep learning techniques is the Convolutional Neural Networks. CNNs are mainly used for image classification although you may find other application areas such as natural language processing.\n",
    "\n",
    "We are capable of using many different layers in a convolutional neural network. However, convolution, pooling, and fully connect layers are the most important ones.\n",
    "\n",
    "# Layers of CNN\n",
    "\n",
    "1.Convolutional Layers\n",
    "\n",
    "Convolutional layer is the very first layer where we extract features from the images in our datasets.\n",
    "\n",
    "2.Pooling Layer\n",
    "\n",
    "When constructing CNNs, it is common to insert pooling layers after each convolution layer to reduce the spatial size of the representation to reduce the parameter counts which reduces the computational complexity.\n",
    "\n",
    "3.A Set of Fully Connected Layers\n",
    "\n",
    "A fully connected network is our RegularNet where each parameter is linked to one another to determine the true relation and effect of each parameter on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3704f1d9e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Viewing randon index entry\n",
    "import matplotlib.pyplot as plt\n",
    "image_index = 9999\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the shape of train and test data for implementing in keras library\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries for neural network construction\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network layers (including convolution)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0,2))\n",
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 47s 786us/step - loss: 0.1848 - acc: 0.9438\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 46s 772us/step - loss: 0.0610 - acc: 0.9812\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 46s 771us/step - loss: 0.0372 - acc: 0.9881\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 47s 780us/step - loss: 0.0236 - acc: 0.9925\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 47s 780us/step - loss: 0.0182 - acc: 0.9938\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 47s 782us/step - loss: 0.0125 - acc: 0.9960\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.0107 - acc: 0.9964\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 50s 837us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 47s 788us/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.0077 - acc: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37071acb38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilimg and training the model\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 206us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07867970041559093, 0.9838]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model for accuracy\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 98.38 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
